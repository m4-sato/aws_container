import os
import json
import uuid
import boto3
import streamlit as st
from dotenv import load_dotenv
from botocore.exceptions import ClientError
from botocore.eventstream import EventStreamError

# LangChain imports
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_aws import BedrockChat
from langchain.chains import LLMChain
from langchain_community.callbacks import StreamlitCallbackHandler
from langsmith import traceable

load_dotenv()
# LangSmith ã®è¨­å®š
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = os.getenv("LANGCHAIN_API_KEY")
os.environ["LANGCHAIN_PROJECT"] = "bedrock-agent-monitoring"


def initialize_session():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸè¨­å®šã‚’è¡Œã†"""
    if "bedrock_client" not in st.session_state:
        st.session_state.bedrock_client = boto3.client("bedrock-runtime", region_name="us-west-2")
    
    if "agent_client" not in st.session_state:
        st.session_state.agent_client = boto3.client("bedrock-agent-runtime", region_name="us-west-2")
    
    if "session_id" not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
    
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "last_prompt" not in st.session_state:
        st.session_state.last_prompt = None
    
    if "llm" not in st.session_state:
        # Bedrock LLMè¨­å®š
        model_id = "anthropic.claude-3-sonnet-20240229-v1:0"  # ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®IDã«å¤‰æ›´
        st.session_state.llm = BedrockChat(
            model_id=model_id,
            client=st.session_state.bedrock_client,
            streaming=True,
            model_kwargs={"temperature": 0.7, "max_tokens": 2000}
        )
    
    return st.session_state.agent_client, st.session_state.session_id, st.session_state.messages, st.session_state.llm


def display_chat_history(messages):
    """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤ºã™ã‚‹"""
    st.title("ã‚ãŒå®¶ã®AIæŠ€è¡“é¡§å•")
    st.text("ç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒã‚¯ã‚¹ã‹ã‚‰ä½•ã§ã‚‚è³ªå•ã—ã¦ã­ï¼")
    
    for message in messages:
        with st.chat_message(message['role']):
            st.markdown(message['text'])


def handle_trace_event(event):
    """ãƒˆãƒ¬ãƒ¼ã‚¹ã‚¤ãƒ™ãƒ³ãƒˆã®å‡¦ç†ã‚’è¡Œã†"""
    if "orchestrationTrace" not in event["trace"]["trace"]:
        return
    
    trace = event["trace"]["trace"]["orchestrationTrace"]
    
    # ã€Œãƒ¢ãƒ‡ãƒ«å…¥åŠ›ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã®è¡¨ç¤º
    if "modelInvocationInput" in trace:
        with st.expander("ğŸ¤” æ€è€ƒä¸­â€¦", expanded=False):
            input_trace = trace["modelInvocationInput"]["text"]
            try:
                st.json(json.loads(input_trace))
            except:
                st.write(input_trace)
    
    # ã€Œãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã®è¡¨ç¤º
    if "modelInvocationOutput" in trace:
        output_trace = trace["modelInvocationOutput"]["rawResponse"]["content"]
        with st.expander("ğŸ’¡ æ€è€ƒãŒã¾ã¨ã¾ã‚Šã¾ã—ãŸ", expanded=False):
            try:
                thinking = json.loads(output_trace)["content"][0]["text"]
                if thinking:
                    st.write(thinking)
                else:
                    st.write(json.loads(output_trace)["content"][0])
            except:
                st.write(output_trace)
    
    # ã€Œæ ¹æ‹ ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã®è¡¨ç¤º
    if "rationale" in trace:
        with st.expander("âœ… æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®šã—ã¾ã—ãŸ", expanded=True):
            st.write(trace["rationale"]["text"])
    
    # ã€Œãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã®è¡¨ç¤º
    if "invocationInput" in trace:
        invocation_type = trace["invocationInput"]["invocationType"]
        
        if invocation_type == "AGENT_COLLABORATOR":
            # ã‚­ãƒ¼ 'agentCollaboratorInvocationInput' ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã™ã‚‹
            if "agentCollaboratorInvocationInput" in trace["invocationInput"]:
                agent_input = trace["invocationInput"]["agentCollaboratorInvocationInput"]
                
                # .get() ã‚’ä½¿ã£ã¦å®‰å…¨ã«ã‚­ãƒ¼ã®å€¤ã‚’å–å¾—ã™ã‚‹
                agent_name = agent_input.get("agentCollaboratorName", "ä¸æ˜ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ") 
                input_data = agent_input.get("input", {})
                input_text = input_data.get("text", "å…¥åŠ›å†…å®¹ä¸æ˜")

                with st.expander(f"ğŸ¤– ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€Œ{agent_name}ã€ã‚’å‘¼ã³å‡ºã—ä¸­â€¦", expanded=True):
                    st.write(input_text)
            else:
                st.warning(f"âš ï¸ AGENT_COLLABORATOR ãƒˆãƒ¬ãƒ¼ã‚¹ã§äºˆæœŸã›ã¬æ§‹é€ ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")
                try:
                    st.json(trace["invocationInput"])
                except:
                     st.write(trace["invocationInput"])

    # ã€Œè¦³å¯Ÿã€ãƒˆãƒ¬ãƒ¼ã‚¹ã®è¡¨ç¤º
    if "observation" in trace:
        # .get() ã‚’ä½¿ã£ã¦å®‰å…¨ã« type ã‚’å–å¾—
        obs_type = trace["observation"].get("type")

        if obs_type == "KNOWLEDGE_BASE":
            # ã‚­ãƒ¼ 'knowledgeBaseLookupOutput' ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            if "knowledgeBaseLookupOutput" in trace["observation"]:
                kb_output = trace["observation"]["knowledgeBaseLookupOutput"]
                # .get() ã‚’ä½¿ã£ã¦å®‰å…¨ã«ã‚¢ã‚¯ã‚»ã‚¹
                retrieved_refs = kb_output.get("retrievedReferences", []) 
                with st.expander("ğŸ” ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æ¤œç´¢çµæœã‚’å–å¾—ã—ã¾ã—ãŸ", expanded=False):
                    st.write(retrieved_refs)
            else:
                st.warning("âš ï¸ KNOWLEDGE_BASE è¦³å¯Ÿãƒˆãƒ¬ãƒ¼ã‚¹ã§äºˆæœŸã›ã¬æ§‹é€ ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")
                try:
                    st.json(trace["observation"])
                except Exception as e:
                     st.write(f"è¦³å¯Ÿãƒˆãƒ¬ãƒ¼ã‚¹å†…å®¹ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                     st.write(trace["observation"])

        elif obs_type == "AGENT_COLLABORATOR":
            # ã‚­ãƒ¼ 'agentCollaboratorInvocationOutput' ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            if "agentCollaboratorInvocationOutput" in trace["observation"]:
                agent_output_data = trace["observation"]["agentCollaboratorInvocationOutput"]
                # .get() ã‚’ä½¿ã£ã¦å®‰å…¨ã«ã‚¢ã‚¯ã‚»ã‚¹
                agent_name = agent_output_data.get("agentCollaboratorName", "ä¸æ˜ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
                output_content = agent_output_data.get("output", {})
                output_text = output_content.get("text", "å‡ºåŠ›å†…å®¹ä¸æ˜")

                with st.expander(f"ğŸ¤– ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€Œ{agent_name}ã€ã‹ã‚‰å›ç­”ã‚’å–å¾—ã—ã¾ã—ãŸ", expanded=True):
                    st.write(output_text)
            else:
                st.warning("âš ï¸ AGENT_COLLABORATOR è¦³å¯Ÿãƒˆãƒ¬ãƒ¼ã‚¹ã§äºˆæœŸã›ã¬æ§‹é€ ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")
                try:
                    st.json(trace["observation"])
                except Exception as e:
                     st.write(f"è¦³å¯Ÿãƒˆãƒ¬ãƒ¼ã‚¹å†…å®¹ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                     st.write(trace["observation"])
            
        else:
            if obs_type:
                st.warning(f"æœªå¯¾å¿œã®è¦³å¯Ÿã‚¿ã‚¤ãƒ—: {obs_type}")
            else:
                st.warning("è¦³å¯Ÿãƒˆãƒ¬ãƒ¼ã‚¹ã« 'type' ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            try:
                st.json(trace["observation"])
            except Exception as e:
                st.write(f"è¦³å¯Ÿãƒˆãƒ¬ãƒ¼ã‚¹å†…å®¹ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                st.write(trace["observation"])


@traceable
def process_with_langchain(llm, user_input, history):
    """LangChainã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‡¦ç†ã™ã‚‹"""
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    system_prompt = """
    ã‚ãªãŸã¯ã€Œã‚ãŒå®¶ã®AIæŠ€è¡“é¡§å•ã€ã§ã™ã€‚
    å®¶åº­å†…ã§ã®æŠ€è¡“çš„ãªè³ªå•ã«å¯¾ã—ã¦ã€è¦ªåˆ‡ã§åˆ†ã‹ã‚Šã‚„ã™ã„å›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
    ç‰¹ã«AIã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã€IoTã€å®¶åº­å†…ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«é–¢ã™ã‚‹è³ªå•ã«è©³ã—ãç­”ãˆã¦ãã ã•ã„ã€‚
    é›£ã—ã„æŠ€è¡“ç”¨èªã¯é¿ã‘ã€ä¸€èˆ¬ã®æ–¹ã«ã‚‚ç†è§£ã—ã‚„ã™ã„è¨€è‘‰ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
    """
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’LangChainå½¢å¼ã«å¤‰æ›
    chat_history = []
    for msg in history:
        if msg['role'] == 'human':
            chat_history.append(HumanMessage(content=msg['text']))
        elif msg['role'] == 'assistant':
            chat_history.append(AIMessage(content=msg['text']))
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä½œæˆ
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        *[(msg.type, msg.content) for msg in chat_history],
        ("human", "{input}")
    ])
    
    # LLMãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆ
    chain = prompt | llm
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ç”¨ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©
    st_callback = StreamlitCallbackHandler(st.empty())
    
    # ãƒã‚§ãƒ¼ãƒ³ã‚’å®Ÿè¡Œ
    result = chain.invoke(
        {"input": user_input},
        config={"callbacks": [st_callback]}
    )
    
    return result.content


def invoke_bedrock_agent(client, session_id, prompt):
    """Bedrockã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã™"""
    load_dotenv()
    return client.invoke_agent(
        agentId=os.getenv("AGENT_ID"),
        agentAliasId=os.getenv("AGENT_ALIAS_ID"),
        sessionId=session_id,
        enableTrace=True,
        inputText=prompt,
    )


def handle_agent_response(response, messages):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†ã™ã‚‹"""
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        for event in response.get("completion"):
            if "trace" in event:
                handle_trace_event(event)
            
            if "chunk" in event:
                chunk = event["chunk"]["bytes"].decode()
                full_response += chunk
                message_placeholder.markdown(full_response + "â–Œ")
        
        message_placeholder.markdown(full_response)
        messages.append({"role": "assistant", "text": full_response})


def show_error_popup(exception_type):
    """ã‚¨ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ã‚’è¡¨ç¤ºã™ã‚‹"""
    if exception_type == "dependencyFailedException":
        error_message = "ã€ã‚¨ãƒ©ãƒ¼ã€‘ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®Aurora DBãŒã‚¹ãƒªãƒ¼ãƒ—ã—ã¦ã„ãŸã‚ˆã†ã§ã™ã€‚æ•°ç§’ãŠã„ã¦ã‹ã‚‰ã€ãƒ–ãƒ©ã‚¦ã‚¶ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ğŸ™"
    elif exception_type == "throttlingException":
        error_message = "ã€ã‚¨ãƒ©ãƒ¼ã€‘Bedrockã®ãƒ¢ãƒ‡ãƒ«è² è·ãŒé«˜ã„ã‚ˆã†ã§ã™ã€‚1åˆ†å¾…ã£ã¦ã‹ã‚‰ã€ãƒ–ãƒ©ã‚¦ã‚¶ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ğŸ™ï¼ˆæ”¹å–„ã—ãªã„å ´åˆã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›´ã™ã‚‹ã‹[ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ã‚©ãƒ¼ã‚¿ã®å¼•ãä¸Šã’ç”³è«‹](https://aws.amazon.com/jp/blogs/news/generative-ai-amazon-bedrock-handling-quota-problems/)ã‚’å®Ÿæ–½ãã ã•ã„ï¼‰"
    st.error(error_message)


def main():
    """ãƒ¡ã‚¤ãƒ³ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†"""
    agent_client, session_id, messages, llm = initialize_session()
    display_chat_history(messages)
    
    if prompt := st.chat_input("ä¾‹ï¼šç”»åƒå…¥ã‚Šè³‡æ–™ã‚’ä½¿ã£ãŸRAGã‚¢ãƒ—ãƒªã‚’ä½œã‚‹ã«ã¯ã©ã†ã™ã‚Œã°ã„ã„ï¼Ÿ"):
        messages.append({"role": "human", "text": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ãƒ¢ãƒ¼ãƒ‰é¸æŠ: ã“ã“ã§Bedrock Agentã¨LangChainãƒ™ãƒ¼ã‚¹ã®ã©ã¡ã‚‰ã‹ã‚’é¸æŠå¯èƒ½
        use_agent = st.session_state.get("use_bedrock_agent", True)
        
        try:
            if use_agent:
                # Bedrock Agentã‚’ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰
                response = invoke_bedrock_agent(agent_client, session_id, prompt)
                handle_agent_response(response, messages)
            else:
                # LangChainã‚’ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰
                with st.chat_message("assistant"):
                    response = process_with_langchain(llm, prompt, messages[:-1])  # æœ€æ–°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’é™¤å¤–
                    st.markdown(response)
                    messages.append({"role": "assistant", "text": response})
            
        except (EventStreamError, ClientError) as e:
            if "dependencyFailedException" in str(e):
                show_error_popup("dependencyFailedException")
            elif "throttlingException" in str(e):
                show_error_popup("throttlingException")
            else:
                raise e


# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿ã‚’è¿½åŠ 
def sidebar():
    with st.sidebar:
        st.title("è¨­å®š")
        st.session_state.use_bedrock_agent = st.checkbox(
            "Bedrock Agentã‚’ä½¿ç”¨", 
            value=st.session_state.get("use_bedrock_agent", True),
            help="ã‚ªãƒ•ã«ã™ã‚‹ã¨LangChainãƒ™ãƒ¼ã‚¹ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒ£ãƒƒãƒˆã«åˆ‡ã‚Šæ›¿ã‚ã‚Šã¾ã™"
        )


if __name__ == "__main__":
    sidebar()
    main()